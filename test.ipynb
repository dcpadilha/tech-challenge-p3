{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import opendatasets as od\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_load(url, streaming=True):\n",
    "    od.download(url, data_dir='downloads', force=True)\n",
    "    folder_name = url.split('/')[-1]\n",
    "    \n",
    "    dataset_name = folder_name.split('-')[1]\n",
    "    df = pd.read_csv(f'downloads/{folder_name}/data.csv')\n",
    "    print(f'{dataset_name}: {df.shape}')\n",
    "\n",
    "    if streaming:\n",
    "        # Verifique o formato dos dados\n",
    "        df['availableCountries'] = df['availableCountries'].apply(lambda x: x.split(',') if isinstance(x, str) else x)\n",
    "\n",
    "        # Remova espaços em branco\n",
    "        df['availableCountries'] = df['availableCountries'].apply(lambda x: [country.strip() for country in x])\n",
    "\n",
    "        # Aplique o MultiLabelBinarizer\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        transformed_array = mlb.fit_transform(df['availableCountries'])\n",
    "        df = df.join(pd.DataFrame(transformed_array, columns=mlb.classes_))\n",
    "\n",
    "        # Verifique a presença de BR\n",
    "        df['contains_BR'] = df['availableCountries'].apply(lambda x: 'BR' in x)\n",
    "\n",
    "        # Adiciona a coluna streaming\n",
    "        df[f'on_{dataset_name}'] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple = get_and_load('https://www.kaggle.com/datasets/octopusteam/full-apple-tv-dataset')\n",
    "df_amazon = get_and_load('https://www.kaggle.com/datasets/octopusteam/full-amazon-prime-dataset')\n",
    "df_netflix = get_and_load('https://www.kaggle.com/datasets/octopusteam/full-netflix-dataset')\n",
    "df_hbo = get_and_load('https://www.kaggle.com/datasets/octopusteam/full-hbo-max-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hbo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat([df_apple, df_amazon, df_netflix, df_hbo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs.on_apple.value_counts())\n",
    "print(dfs.on_amazon.value_counts())\n",
    "print(dfs.on_hbo.value_counts())\n",
    "print(dfs.on_netflix.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.BR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = get_and_load('https://www.kaggle.com/datasets/octopusteam/full-imdb-dataset', streaming=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(dfs, df_imdb, left_on='imdbId', right_on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
